{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931d0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as tr\n",
    "import torch.nn as nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "import phi4_mg as m\n",
    "\n",
    "\n",
    "#!/usr/local/bin/python3\n",
    "import time\n",
    "import numpy as np\n",
    "import torch as tr\n",
    "import phi4 as s\n",
    "import integrators as i\n",
    "import update as u\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from stacked_model import *\n",
    "import Gamma_error as gm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7669d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/sciclone/home/yacahuanamedra/texlive/bin/x86_64-linux:\" + os.environ[\"PATH\"]\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex', preamble=r'\\usepackage{amsmath} \\usepackage{amsfonts}')\n",
    "import pickle\n",
    "\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 30}\n",
    "\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 30}\n",
    "\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15ae27",
   "metadata": {},
   "source": [
    "## Real NVP and grid classes for MCMG+NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca75a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "import torch.nn as nn\n",
    "\n",
    "class RGlayer1(nn.Module):\n",
    "    def __init__(self, transformation_type=\"select\", batch_size=1, dtype=tr.float64, device=\"cpu\"):\n",
    "        super(RGlayer1, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "\n",
    "        if transformation_type == \"select\":\n",
    "            mask_c = [[1.0, 0.0], [0.0, 0.0]]\n",
    "            mask_r = [[1.0, 1.0], [1.0, 1.0]]\n",
    "        elif transformation_type == \"average\":\n",
    "            mask_c = [[0.25, 0.25], [0.25, 0.25]]\n",
    "            mask_r = [[1.0, 1.0], [1.0, 1.0]]\n",
    "        else:\n",
    "            print(\"Unknown RG blocking transformation. Using default.\")\n",
    "            mask_c = [[1.0, 0.0], [0.0, 0.0]]\n",
    "            mask_r = [[1.0, 0.0], [0.0, 0.0]]\n",
    "\n",
    "        self.type = transformation_type\n",
    "\n",
    "        self.restrict = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(2, 2), stride=2, bias=False)\n",
    "        self.restrict.weight = nn.Parameter(tr.tensor([[mask_c]], dtype=self.dtype, device=self.device), requires_grad=False)\n",
    "        self.prolong = nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=(2, 2), stride=2, bias=False)\n",
    "        self.prolong.weight = nn.Parameter(tr.tensor([[mask_r]], dtype=self.dtype, device=self.device), requires_grad=False)\n",
    "\n",
    "    def coarsen(self, f):\n",
    "        #print(\"coarsen device: \", f.device, f.dtype)\n",
    "        ff = f.view(f.shape[0], 1, f.shape[1], f.shape[2])\n",
    "        c = self.restrict(ff)\n",
    "        r = ff - self.prolong(c)\n",
    "        return (c.squeeze(1), r.squeeze(1)) if self.batch_size == 1 else (c.squeeze(), r.squeeze())\n",
    "\n",
    "    def refine(self, c, r):\n",
    "        cc = c.view(c.shape[0], 1, c.shape[1], c.shape[2])\n",
    "        rr = r.view(r.shape[0], 1, r.shape[1], r.shape[2])\n",
    "        return (self.prolong(cc) + rr).squeeze(1) if self.batch_size == 1 else (self.prolong(cc) + rr).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22489a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class phi4_c1:\n",
    "    def action(self,phi_c):\n",
    "        rphis=[]\n",
    "        rphis.append(phi_c)\n",
    "        iii=0\n",
    "        logdet_total=tr.zeros(phi_c.shape[0],dtype=self.dtype,device=self.device)\n",
    "        for pi in reversed(self.pics):\n",
    "            #print(pi.shape)\n",
    "            rphi = self.rg.refine(rphis[iii],pi)\n",
    "            if self.mode==\"rnvp\":\n",
    "                #flowback through the network\n",
    "                #rphi,logdet = self.mgf.cflow[self.level-1-iii].backward(rphi)\n",
    "                #logdet_total+=logdet\n",
    "                rphi = self.mgf.cflow[self.level-1-iii].forward(rphi)\n",
    "                logdet_total+=self.mgf.cflow[self.level-1-iii].log_prob(rphi)\n",
    "                #print(\"log_det\",logdet_total,\"level\",self.level-1-iii)\n",
    "            #print(\"log_det\",logdet,\"level\",self.level-1-iii)\n",
    "            rphis.append(rphi)\n",
    "            iii+=1\n",
    "        #phi_f = rphis[-1]\n",
    "        #evaluate coarse field in action of rg\n",
    "        #print(phi_f.shape,\"shape of fine field\")\n",
    "        return self.sg.action(rphi)+logdet_total ## NANs\n",
    "        #if I dont add the .sum() I got a grad for the batch system, it seems to me that we include that in the force property the batch is summed?\n",
    "\n",
    "    def force(self, phi_c):\n",
    "        x_tensor = phi_c.clone().requires_grad_()\n",
    "\n",
    "        S = self.action(x_tensor)\n",
    "        grad = tr.autograd.grad(S.sum(), x_tensor, retain_graph=False)[0]\n",
    "\n",
    "        if grad is None:\n",
    "            print(\"[ERROR] Gradient is None.\")\n",
    "            raise RuntimeError(\"autograd.grad returned None.\")\n",
    "        #release memory on gpu\n",
    "        return -grad.detach()\n",
    "    \n",
    "    def refreshP(self):\n",
    "        P = tr.normal(0.0,1.0,self.phis[-1].shape).to(self.device).to(self.dtype)#only difference with fine level\n",
    "        return P\n",
    "\n",
    "    def evolveQ(self,dt,P,Q):\n",
    "        return Q + dt*P\n",
    "    \n",
    "    def kinetic(self,P):\n",
    "        return tr.einsum('bxy,bxy->b',P,P)/2.0\n",
    "\n",
    "    def generate_cfg_levels(self,phi11):#run every time we need to contruct deeper or superficial levels\n",
    "        #run a configuration\n",
    "        self.level = self.mgf.depth\n",
    "        phis=[]\n",
    "        pis=[]\n",
    "        phicopy=phi11.clone().to(self.device).to(self.dtype)\n",
    "        \n",
    "        #print(\"shape of the original field\",phicopy.shape)\n",
    "        phis.append(phicopy)\n",
    "        # print(\"coarsening level init field shape \",phicopy.shape)\n",
    "        for step in range(self.level):\n",
    "            if self.mode==\"rnvp\":\n",
    "                \n",
    "                phicopy,logdet = self.mgf.cflow[step].backward(phicopy)\n",
    "                #create an extra dimension for batch\n",
    "                #if self.sg.Bs==1:\n",
    "                #    phicopy=phicopy.unsqueeze(0)\n",
    "                \n",
    "                #print(\"device phicopy \",phicopy.device,\" dtype \",phicopy.dtype)\n",
    "            #print(\"coarsening level \",_,\" field shape \",phicopy.shape)\n",
    "            #print(\"coarsening level \",step,\" field shape \",phicopy.shape)\n",
    "            phic,pic = self.rg.coarsen(phicopy)\n",
    "\n",
    "            phis.append(phic)\n",
    "            pis.append(pic)\n",
    "            phicopy=phic\n",
    "        self.phis=phis\n",
    "        self.pics=pis\n",
    "\n",
    "        #reversed\n",
    "        rphis=[]\n",
    "        \n",
    "        rphis.append(phis[-1])\n",
    "        #self.mgf.cflow[step].backward(rphis[0])\n",
    "        sss=0\n",
    "        for phics,pis in zip(reversed(phis),reversed(pis)):\n",
    "            \n",
    "            rphi = self.rg.refine(phics,pis)\n",
    "            #flowback through the network\n",
    "            if self.mode==\"rnvp\":\n",
    "                rphi = self.mgf.cflow[self.level-1-sss].forward(rphi)\n",
    "                #print(\"log_det\",logdet,\"level\",self.level-1-sss)\n",
    "            sss+=1\n",
    "            \n",
    "            rphis.append(rphi)\n",
    "        self.rphis=rphis\n",
    "\n",
    "    def __init__(self,sgg,mgf,device=\"cpu\",dtype=tr.float64,mode=\"rnvp\"):\n",
    "        self.sg = sgg #theory? in the finest level\n",
    "        self.mgf = mgf #neural net\n",
    "        self.rg = mgf.rg #projector to coarse level\n",
    "        self.mode = mode\n",
    "        print(\"multigrid is done by: \",self.mode)\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37d2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MGflow1(nn.Module):\n",
    "    def __init__(self,size,bijector,rg,prior,Nconvs=2,depth=None):\n",
    "        super(MGflow1, self).__init__()\n",
    "        self.prior=prior\n",
    "        self.rg=rg\n",
    "        self.size = size\n",
    "        minSize = min(size)\n",
    "        print(\"Initializing MGflow module with size: \",minSize)\n",
    "        if depth==None:\n",
    "            self.depth = int(np.log(minSize)/np.log(2))\n",
    "        else:\n",
    "            self.depth = depth\n",
    "        print(\"Using depth: \", self.depth)\n",
    "        print(\"Using rg type: \",rg.type)\n",
    "        sizes = []\n",
    "        for k in range(self.depth):\n",
    "            sizes.append([int(size[i]/(2**k)) for i in range(len(size))])\n",
    "            print(\"(depth, size): \", k, sizes[-1])\n",
    "            \n",
    "            \n",
    "        # the module list are ordered from fine to coarse\n",
    "        self.cflow=tr.nn.ModuleList([m.ConvFlowLayer(sizes[k],bijector,Nconvs) for k in range(self.depth)])\n",
    "\n",
    "    #noise to fields\n",
    "    def forward(self,z):\n",
    "        x = z\n",
    "        \n",
    "        # can I use lists and still expect autgrad to work?\n",
    "        fines = []\n",
    "        #take the noise to the coarsest level\n",
    "        for k in range(self.depth-1):\n",
    "            c,f =self.rg.coarsen(x)\n",
    "            #print(c.shape,f.shape)\n",
    "            x=c\n",
    "            fines.append(f)\n",
    "        #print(\"Number of fine levels: \", len(fines))\n",
    "        # now reverse order to get back to fine\n",
    "        # x should now be coarsest possible\n",
    "        #print(\"Size of x: \", x.shape)\n",
    "        for k in range(self.depth-1,0,-1):\n",
    "            #print(k)\n",
    "            fx=self.cflow[k](x)\n",
    "            x=self.rg.refine(fx,fines[k-1])\n",
    "        fx = self.cflow[0](x)\n",
    "        #print(\"Size of fx at the end:\",fx.shape)\n",
    "        \n",
    "        return fx\n",
    "\n",
    "    #fields to noise\n",
    "    def backward(self,x):\n",
    "        log_det_J=x.new_zeros(x.shape[0])\n",
    "\n",
    "        # can I use lists and still expect autgrad to work?\n",
    "        fines = []\n",
    "        for k in range(self.depth-1):\n",
    "            #print(k,\"shape(x)\",x.shape)\n",
    "            fx,J = self.cflow[k].backward(x)\n",
    "            log_det_J += J\n",
    "            cx,ff = self.rg.coarsen(fx)\n",
    "            fines.append(ff)\n",
    "            x=cx\n",
    "        #print(\"end\",\"shape(x)\",x.shape)\n",
    "        #for k in range(len(fines)):\n",
    "            #print(k,\"shape of fines\",fines[k].shape)\n",
    "        fx,J = self.cflow[self.depth-1].backward(x)\n",
    "        log_det_J += J\n",
    "        #move the noise to the finest level\n",
    "        for k in range(self.depth-2,-1,-1):\n",
    "            #print(k,\"sizes\", fx.shape,fines[k].shape)\n",
    "            z=self.rg.refine(fx,fines[k])\n",
    "            #print(\"Size of z at the end:\",z.shape)\n",
    "            #print(\"fx at the end:\",fx.shape)  \n",
    "            fx=z\n",
    "        return fx,log_det_J\n",
    "\n",
    "    def log_prob(self,x):\n",
    "        z, logp = self.backward(x)\n",
    "        #print(\"In log prob z.shape: \", z.shape)\n",
    "        #print(\"In log prob z.shape: \", z.shape)\n",
    "        return self.prior.log_prob(z.flatten(start_dim=1)) + logp\n",
    "\n",
    "    def sample(self, batchSize): \n",
    "        #z = self.prior.sample((batchSize, 1)).reshape(batchSize,self.size[0],self.size[1])\n",
    "        z = self.prior_sample(batchSize)\n",
    "        x = self.forward(z)\n",
    "        return x\n",
    "\n",
    "    # generate a sample from the prior\n",
    "    def prior_sample(self,batch_size):\n",
    "        return self.prior.sample((batch_size,1)).reshape(batch_size,self.size[0],self.size[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc449955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#still need to change the code of phi_coarse try Vcycle instead\n",
    "def V_cycle(phi_o,sgc_c,mgf_c,hmc_f,m1,m2,Nskip=1,mode=\"normal\"):#mode=\"rnvp\"\n",
    "    phi_o= hmc_f.evolve(phi_o,m1)\n",
    "    sgc = phi4_c1(sgc_c,mgf_c,device=sgc_c.device,dtype=sgc_c.dtype,mode=mode)\n",
    "    mn2c = i.minnorm2(sgc.force,sgc.evolveQ,14,1.0)\n",
    "    hmcc = u.hmc(T=sgc,I=mn2c,verbose=True)\n",
    "    sgc.generate_cfg_levels(phi_o)\n",
    "    phic=sgc.phis[-1]\n",
    "    phic_up=hmcc.evolve(phic,Nskip)\n",
    "    #now go back up\n",
    "    for sss in reversed(range(mgf_c.depth)):\n",
    "        phic_up= mgf_c.rg.refine(phic_up,sgc.pics[sss])\n",
    "    \n",
    "    #print(\"shape of fine field \",phic_up.shape)\n",
    "    phic_up=hmc_f.evolve(phic_up,m2)\n",
    "    return phic_up, hmcc.AcceptReject\n",
    "\n",
    "#get_observables_MCMG(sg,mgf, hmc, phi, Nwarm, Nmeas, pp=)\n",
    "\n",
    "def get_observables_MCMG(sg,mgf, hmc, phi, Nwarm, Nmeas,pp=\"print\",mode=\"normal\"):\n",
    "\n",
    "    tic=time.perf_counter()\n",
    "    Vol=sg.Vol\n",
    "    lat=[phi.shape[1], phi.shape[2]]\n",
    "    toc=time.perf_counter()\n",
    "\n",
    "    print(f\"time {(toc - tic)*1.0e6/Nwarm:0.4f} micro-seconds per HMC trajecrory\")\n",
    "\n",
    "    lC2p = []\n",
    "    lchi_m = []\n",
    "    E = []\n",
    "    av_phi = []\n",
    "    phase=tr.tensor(np.exp(1j*np.indices(tuple(lat))[0]*2*np.pi/lat[0]),dtype=sg.dtype,device=sg.device)\n",
    "    for k in range(Nmeas):\n",
    "        ttE = sg.action(phi)/Vol\n",
    "        E.extend(ttE)\n",
    "        av_sigma = tr.mean(phi.view(sg.Bs,Vol),axis=1)\n",
    "        av_phi.extend(av_sigma)\n",
    "        chi_m = av_sigma*av_sigma*Vol\n",
    "        p1_av_sig = tr.mean(phi.view(sg.Bs,Vol)*phase.view(1,Vol),axis=1)\n",
    "        C2p = tr.real(tr.conj(p1_av_sig)*p1_av_sig)*Vol\n",
    "        if(k%10==0) and pp==\"print\":\n",
    "            print(\"k= \",k,\"(av_phi,chi_m, c2p, E) \", av_sigma.mean().detach().numpy(),chi_m.mean().detach().numpy(),C2p.mean().detach().numpy(),ttE.mean().detach().numpy())\n",
    "        lC2p.extend(C2p)\n",
    "        lchi_m.extend(chi_m)\n",
    "        ## HMC update but also V cycle\n",
    "        phi,accept=V_cycle(phi,sg,mgf,hmc,1,1,Nskip=Nskip,mode=mode)\n",
    "\n",
    "    return lC2p, lchi_m, E, av_phi, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949fa39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 16]) 256 tensor(-0.0037, device='cuda:0') tensor(1.0154, device='cuda:0')\n",
      "Initializing MGflow module with size:  16\n",
      "Using depth:  1\n",
      "Using rg type:  average\n",
      "(depth, size):  0 [16, 16]\n"
     ]
    }
   ],
   "source": [
    "import integrators as i\n",
    "import mgmc as mgmc\n",
    "\n",
    "\n",
    "device = tr.device('cuda:0')\n",
    "dtype=tr.float32\n",
    "L=16\n",
    "lat = [L,L]\n",
    "V=L*L\n",
    "# This set of params is very very close to critical.\n",
    "lam = 2.4\n",
    "mas = -0.55\n",
    "\n",
    "normal = distributions.Normal(tr.zeros(V,dtype=dtype,device=device),tr.ones(V,dtype=dtype,device=device))\n",
    "prior= distributions.Independent(normal, 1)\n",
    "\n",
    "\n",
    "Nwarm = 1\n",
    "Nmeas = 1000\n",
    "Nskip = 1\n",
    "batch_size = 20\n",
    "\n",
    "Vol = np.prod(lat)\n",
    "sg = s.phi4(lat,lam,mas,batch_size=batch_size,device=device,dtype=dtype)\n",
    "phi = sg.hotStart()\n",
    "\n",
    "\n",
    "#clone phi\n",
    "phi2 = phi.clone()\n",
    "\n",
    "\n",
    "mn2 = i.minnorm2(sg.force,sg.evolveQ,14,1.0)\n",
    "print(phi.shape,Vol,tr.mean(phi),tr.std(phi))\n",
    "hmc = u.hmc(T=sg,I=mn2,verbose=False)\n",
    "\n",
    "FLOW=lambda: m.FlowBijectorParity(Nlayers=1,width=32)\n",
    "\n",
    "mgf=MGflow1([L,L],FLOW,RGlayer1(\"average\",batch_size=batch_size,dtype=dtype,device=device),prior,depth=1).to(device)#.double()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51978e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter count:  21608\n",
      "iter 0: loss = 33.585\n",
      "iter 50: loss = -50.972\n",
      "iter 100: loss = -76.643\n",
      "iter 150: loss = -86.485\n",
      "iter 200: loss = -91.092\n",
      "iter 250: loss = -93.121\n",
      "iter 300: loss = -93.010\n",
      "iter 350: loss = -94.141\n",
      "iter 400: loss = -93.890\n",
      "iter 450: loss = -93.666\n",
      "iter 500: loss = -94.375\n",
      "iter 550: loss = -94.066\n",
      "iter 600: loss = -94.619\n",
      "iter 650: loss = -94.698\n",
      "iter 700: loss = -95.186\n",
      "iter 750: loss = -95.917\n",
      "iter 800: loss = -96.074\n",
      "iter 850: loss = -96.571\n",
      "iter 900: loss = -96.714\n",
      "iter 950: loss = -96.821\n",
      "iter 1000: loss = -97.498\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for tt in mgf.parameters():\n",
    "    #print(tt.shape)\n",
    "    c+=tt.numel()\n",
    "\n",
    "print(\"parameter count: \",c)\n",
    "#set parameters to 0\n",
    "#for p in mgf.parameters():\n",
    "#    p.data.zero_()\n",
    "\n",
    "optimizer = tr.optim.Adam([p for p in mgf.parameters() if p.requires_grad==True], lr=1e-4)\n",
    "\n",
    "loss_history = []\n",
    "super_batch_size = 10\n",
    "for t in range(1001):   \n",
    "    #with torch.no_grad():\n",
    "    #z = prior.sample((batch_size,1)).squeeze().reshape(batch_size,L,L)\n",
    "    z = mgf.prior_sample(batch_size)\n",
    "    #print(z.shape,z.device)\n",
    "    x = mgf(z) # generate a sample\n",
    "    #print(x.shape,x.device)\n",
    "    tloss = (mgf.log_prob(x)+sg.action(x))\n",
    "    for b in range(1,super_batch_size):\n",
    "        z = mgf.prior_sample(batch_size)\n",
    "        x = mgf(z) # generate a sample\n",
    "        tloss += (mgf.log_prob(x)+sg.action(x)) # KL divergence (or not?)\n",
    "    loss =tloss.mean()/super_batch_size\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    loss_history.append(loss.cpu().detach().numpy())\n",
    "    #print(loss_history[-1])\n",
    "    if t % 50 == 0:\n",
    "        #print(z.shape)\n",
    "        print('iter %s:' % t, 'loss = %.3f' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc5908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torchQFT)",
   "language": "python",
   "name": "torchqft-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
